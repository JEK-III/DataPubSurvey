{
 "metadata": {
  "name": "",
  "signature": "sha256:2f76d3f1066f5ccc2469bee0c9d093fe7d7379a3fb5db56410dd22479ee48daa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You have quite a few non-significant findings reported, and it is not clear whether that is merely due to low power of detecting true findings.\n",
      "\n",
      "My gut feeling is that 250 researcher responses should be enough for adequate power, but since many readers will be skeptical, better that you demonstrate clearly and concretely what the limits of your sensitivity and power are in this particular survey."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PAPER_DISCIPLINE_MAP = {'Anthropology' : 'Social science',\n",
      "                        'Archaeology' : 'Archaeology',\n",
      "                        'Area studies' : 'Social science',\n",
      "                        'Economics' : 'Social science',\n",
      "                        'Political science' : 'Social science',\n",
      "                        'Psychology' : 'Social science',\n",
      "                        'Sociology' : 'Social science',\n",
      "                        'Astronomy' : 'Space science',\n",
      "                        'Astrophysics' : 'Space science',\n",
      "                        'Environmental Science' : 'Environmental science',\n",
      "                        'Geology' : 'Earth science',\n",
      "                        'Oceanography' : 'Environmental science',\n",
      "                        'Planetary science' : 'Earth science',\n",
      "                        'Biochemistry' : 'Biology',\n",
      "                        'Bioinformatics' : 'Biology',\n",
      "                        'Biology' : 'Biology',\n",
      "                        'Evolutionary Biology' : 'Biology',\n",
      "                        'Neurobiology' : 'Biology',\n",
      "                        'Social science' : 'Social science',\n",
      "                        'Space science' : 'Space science',\n",
      "                        'Earth science' : 'Earth science',\n",
      "                        'Life science' : 'Biology',\n",
      "                        'Chemistry' : 'Physical science',\n",
      "                        'Physics' : 'Physical science',\n",
      "                        'Computer science' : 'Computer science',\n",
      "                        'Mathematics' : 'Mathematics',\n",
      "                        'Information science' : 'Information science',\n",
      "                        'Other' : 'Other'} "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def checkbox_chi_square(question, answers, responses_ft=responses):\n",
      "    \n",
      "    # extract checkbox column and split responses into array\n",
      "    #split_checkbox = responses[dvar].str.split(\"; \").dropna()\n",
      "    split_checkbox = responses_ft[question].dropna()\n",
      "\n",
      "\n",
      "    # DF of bools; responders x checkbox (checked = True) \n",
      "    checkbox_responses = pd.DataFrame({name : split_checkbox.apply(lambda x: name in x) for name in answers})\n",
      "\n",
      "    \n",
      "    # DF of pairwise p-values\n",
      "    pvalues = pd.DataFrame(index=answers, columns=answers)\n",
      "\n",
      "    # DF of all the counts to test for overall significance\n",
      "    total_square = pd.DataFrame(index=[True, False], columns=answers)\n",
      "\n",
      "    i=0\n",
      "    for a in answers:\n",
      "        i +=1    \n",
      "        # fill in T and F counts for this answer \n",
      "        total_square[a] = checkbox_responses[a].value_counts()\n",
      "\n",
      "        # separate series \n",
      "\n",
      "        for b in answers[i:]:\n",
      "\n",
      "            # initialize pairwise count table\n",
      "            square = pd.DataFrame({ 0 : 0, 0 : 0}, index=[True, False], columns=[True, False])        \n",
      "\n",
      "            # fill in counts\n",
      "            square[True] = (checkbox_responses[checkbox_responses[a] == True][b].value_counts())\n",
      "            square[False] = (checkbox_responses[checkbox_responses[a] == False][b].value_counts())\n",
      "            \n",
      "\n",
      "            count_table = square.as_matrix()\n",
      "             \n",
      "            \n",
      "            if ~numpy.isnan(count_table).any():\n",
      "                oddsratio, p = sps.fisher_exact(count_table)\n",
      "                pvalues.ix[a, b] = p\n",
      "\n",
      "                    \n",
      "            \n",
      "    t_chi2, t_p, t_df, t_expected = sps.chi2_contingency(total_square.as_matrix())\n",
      "\n",
      "    print \"total chi2= \" + str(t_chi2) + \", p= \" + str(t_p)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'responses' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-2-ccccd8b661fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcheckbox_chi_square\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponses_ft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# extract checkbox column and split responses into array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#split_checkbox = responses[dvar].str.split(\"; \").dropna()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msplit_checkbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponses_ft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'responses' is not defined"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}